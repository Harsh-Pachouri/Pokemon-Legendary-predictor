import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split

import tensorflow as tf
from sklearn.decomposition import PCA


data = pd.read_csv('Pokemon.csv')
data_raw = data.copy()
data.head()

# # and Name not required based on above
data.isna().sum() # checking for null values
data = data.drop(["#","Name","Type 2"],axis=1) #dropping unnecessary and unhelpful columns
data.head()

data['Legendary'] = data['Legendary'].astype(int) # now Legendary is binary column
numeric_columns = data.drop("Type 1",axis=1).columns #All the columns(only names) without "Type 1" which is the only string column remaining.

correlation_matrix = data[numeric_columns].corr() # correlation matrix
plt.figure(figsize=(10,8))
sns.heatmap(correlation_matrix, annot=True,vmin=-1,vmax=1.0)
plt.show()

plt.figure(figsize=(20,10))
for column in ['HP','Attack','Defense','Sp. Atk','Sp. Def','Speed']:
  sns.kdeplot(data[column],fill=True)
plt.show

def onehot_encode(df,column,prefix):
  df=df.copy()
  dummies = pd.get_dummies(df[column],prefix=prefix)
  df=pd.concat([df,dummies],axis=1)
  df=df.drop(column,axis=1)
  return df

data = onehot_encode(data,"Type 1","t"); # "Type 1" columns is one hot encoded
data.head()

y= data['Legendary']
X = data.drop('Legendary',axis=1)
myscaler = StandardScaler()
X = myscaler.fit_transform(X) #data scaled(normalized)
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42) #data split

inputs=tf.keras.Input(shape=(X.shape[1]))
x = tf.keras.layers.Dense(64,activation='relu')(inputs)
x = tf.keras.layers.Dense(64,activation='relu')(x)
outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)
model = tf.keras.Model(inputs=inputs,outputs=outputs)
model.compile(
    loss=tf.keras.losses.BinaryCrossentropy(),
    optimizer=tf.keras.optimizers.Adam(0.001),
    metrics=[
        'accuracy',
        tf.keras.metrics.AUC(name='auc')
    ]
)

batch_size = 32
epochs=20

history=model.fit(
    X_train,
    y_train,
    validation_split = 0.2,
    batch_size=batch_size,
    epochs=epochs,
    callbacks=[tf.keras.callbacks.ReduceLROnPlateau()]
)

fig_loss=px.line(
    history.history,
    y=['loss','val_loss'],
    labels={'x':'epoch','y':'loss'},
     title="Loss Over Time"
)
fig_loss.show()

np.argmin(history.history['val_loss'])

fig_auc=px.line(
    history.history,
    y=['auc','val_auc'],
    labels={'x':'epoch','y':'auc'},
     title="Auc Over Time"
)
fig_auc.show()
.
